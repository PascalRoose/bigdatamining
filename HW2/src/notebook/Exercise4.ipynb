{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import split, explode, monotonically_increasing_id, col, lower, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session/application\n",
    "spark = SparkSession.builder.appName('Exercise 4').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import News_Final.csv as dataframe using the defined schema\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"IDLink\", IntegerType(), True),\n",
    "        StructField(\"Title\", StringType(), True),\n",
    "        StructField(\"Headline\", StringType(), True),\n",
    "        StructField(\"Source\", StringType(), True),\n",
    "        StructField(\"Topic\", StringType(), True),\n",
    "        StructField(\"PublishDate\", TimestampType(), True),\n",
    "        StructField(\"SentimentTitle\", FloatType(), True),\n",
    "        StructField(\"SentimentHeadline\", FloatType(), True),\n",
    "        StructField(\"Facebook\", FloatType(), True),\n",
    "        StructField(\"GooglePlus\", FloatType(), True),\n",
    "        StructField(\"LinkedIn\", FloatType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = spark.read.format(\"csv\")\\\n",
    "               .option(\"header\", \"true\")\\\n",
    "               .option(\"delimiter\", \",\")\\\n",
    "               .option('quote', '\"')\\\n",
    "               .option('escape', '\"')\\\n",
    "               .schema(schema)\\\n",
    "               .load(\"data/News_Final.csv\")\n",
    "\n",
    "# Mutate the dataframe so we only have the colomns we need in the right format\n",
    "# Title and headline will be lowercase and only include alphabetic characters\n",
    "df = df.withColumn('Title', lower(col('Title')))\\\n",
    "       .withColumn('Title', regexp_replace('Title', '[^a-z\\s]', ''))\\\n",
    "       .withColumn('Headline', lower(col('Headline')))\\\n",
    "       .withColumn('Headline', regexp_replace('Headline', '[^a-z\\s]', ''))\\\n",
    "       .select('Title', 'Headline', 'Topic')\n",
    "\n",
    "\n",
    "\n",
    "### search values for the 2 cases\n",
    "cases = ('Headline', 'Title')\n",
    "topics = ('obama', 'economy', 'palestine', 'microsoft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top100(case, topic):\n",
    "    ### Collects all the articles for the topic\n",
    "    df_temp_untop100ed = df.filter(\"Topic == '\"+topic+\"'\")\n",
    "    \n",
    "    ### Explode title or headline, count each word, sort descending and take the first 100 results\n",
    "    df_temp_top100ed = df_temp_untop100ed.withColumn('word', explode(split(col(case), ' ')))\\\n",
    "                                         .groupBy('word')\\\n",
    "                                         .count()\\\n",
    "                                         .sort('count', ascending=False)\\\n",
    "                                         .limit(100)\n",
    "    \n",
    "    # Convert the dataframe to a list\n",
    "    top100 = [row[0] for row in df_temp_top100ed.collect()]\n",
    "    \n",
    "    return top100\n",
    "\n",
    "# Create a dictionary with top100 list for each topic per case\n",
    "top100_dict = {}\n",
    "for case in cases:\n",
    "    top100_dict[case] = {}\n",
    "    for topic in topics:\n",
    "        top100_dict[case][topic] = get_top100(case, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comatrix(case, topic, top100):\n",
    "    # Filter by topic, explode the case (either title or headline)\n",
    "    df_expl = df.filter(\"Topic == '\"+topic+\"'\")\\\n",
    "                .withColumn(\"id\", monotonically_increasing_id())\\\n",
    "                .select(\"id\", explode(split(case, \" \")))\n",
    "    # Filter all of the words, leave only the words that are in the top100\n",
    "    df_fltr = df_expl.filter(df_expl.col.isin(top100))\n",
    "    \n",
    "    # Use join and crosstab to calculate and create a co-occurence matrix\n",
    "    return df_fltr.withColumnRenamed(\"col\", \"col_\")\\\n",
    "                  .join(df_fltr, [\"id\"]).stat.crosstab(\"col_\", \"col\")\n",
    "\n",
    "# Create a dictionary with coocurrence df for each topic per case\n",
    "comatrix_dict = {}\n",
    "for case in cases:\n",
    "    comatrix_dict[case] = {}\n",
    "    for topic in topics:\n",
    "        top100 = top100_dict[case][topic]\n",
    "        comatrix_dict[case][topic] = create_comatrix(case, topic, top100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all of the files\n",
    "for case in cases:\n",
    "    for topic in topics:\n",
    "        comatrix_df = comatrix_dict[case][topic]\n",
    "        \n",
    "        # Grab only the first line with header and write\n",
    "        comatrix_df.limit(1).write.option(\"header\", True).mode(\"overwrite\").csv(f\"output/exercise4/partition/comatrix_{case}_{topic}_header\")\n",
    "        comatrix_df.write.mode(\"overwrite\").csv(f\"output/exercise4/partition/comatrix_{case}_{topic}\")\n",
    "        \n",
    "        # Remove the old file\n",
    "        os.system(f'rm output/exercise4/comatrix_{case}_{topic}.txt')\n",
    "        \n",
    "        # Write the header first (first line of _header with head -1)\n",
    "        os.system(f'head -1 output/exercise4/partition/comatrix_{case}_{topic}_header/p*'\\\n",
    "                  f' > output/exercise4/comatrix_{case}_{topic}.txt')\n",
    "        \n",
    "        # Write all of the partitions to one txt file\n",
    "        os.system(f'cat output/exercise4/partition/comatrix_{case}_{topic}/p*'\\\n",
    "                  f' >> output/exercise4/comatrix_{case}_{topic}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
