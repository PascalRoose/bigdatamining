{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session/application \n",
    "spark = SparkSession.builder.appName('Inputdata').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_hire_stats.csv as dataframe using the defined schema\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"Zone_ID\", ByteType(), False),\n",
    "        StructField(\"Date\", TimestampType(), False),\n",
    "        StructField(\"Hour_slot\", ByteType(), False),\n",
    "        StructField(\"Hire_count\", ShortType(), False)\n",
    "    ]\n",
    ")\n",
    "train_df = spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"delimiter\", \",\")\\\n",
    "        .schema(schema)\\\n",
    "        .load(\"data/train_hire_stats.csv\")\n",
    "\n",
    "train_df = train_df.withColumn('Day_of_the_week', \n",
    "                               (F.date_format(train_df[\"Date\"], \"u\").cast(IntegerType())))\n",
    "\n",
    "train_df = train_df.withColumn('Month', \n",
    "                               (F.date_format(train_df[\"Date\"], \"M\").cast(IntegerType())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import test_hire_stats.csv as dataframe using the defined schema\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"Test_ID\", ShortType(), False),\n",
    "        StructField(\"Zone_ID\", ByteType(), False),\n",
    "        StructField(\"Date\", TimestampType(), False),\n",
    "        StructField(\"Hour_slot\", ByteType(), False),\n",
    "        StructField(\"Hire_count\", ByteType(), False)\n",
    "    ]\n",
    ")\n",
    "test_df = spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"delimiter\", \",\")\\\n",
    "        .schema(schema)\\\n",
    "        .load(\"data/test_hire_stats.csv\")\n",
    "\n",
    "test_df = test_df.withColumn('Day_of_the_week', \n",
    "                             (F.date_format(test_df[\"Date\"], \"u\").cast(IntegerType())))\n",
    "\n",
    "test_df = test_df.withColumn('Month', \n",
    "                             (F.date_format(test_df[\"Date\"], \"M\").cast(IntegerType())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols = ['Zone_ID', 'Hour_slot', 'Day_of_the_week', 'Month'],\n",
    "    outputCol = 'features'\n",
    "    )\n",
    "\n",
    "trainData = assembler.transform(train_df)\n",
    "testData = assembler.transform(test_df)\n",
    "\n",
    "trainData = trainData.withColumn('label', trainData.Hire_count)\n",
    "testData = testData.withColumn('label', testData.Hire_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelIndexer = StringIndexer(inputCol='Hire_count', outputCol='indexedLabel').fit(trainData)\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=24).fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "rf = RandomForestClassifier(labelCol='indexedLabel', featuresCol='indexedFeatures', numTrees=100)\n",
    "rf = rf.setImpurity('Gini')\n",
    "rf = rf.setMaxDepth(10)\n",
    "rf = rf.setFeatureSubsetStrategy('auto')\n",
    "'''\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol = 'indexedFeatures')\n",
    "rf = rf.setMaxDepth(11)\n",
    "rf = rf.setNumTrees(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "\n",
    "model = pipeline.fit(trainData)\n",
    "\n",
    "predictions = model.transform(testData)\n",
    "predictions = predictions.withColumn('Hire_count', predictions.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this when using trainingData to make predicition\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol = 'label', predictionCol = 'prediction', metricName = 'rmse')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = predictions.withColumn(\"Hire_count\", predictions[\"prediction\"].cast(IntegerType()))\n",
    "final_df = final_df.select(\"Test_ID\", \"Zone_ID\", \"Date\", \"Hour_slot\", \"Hire_count\").orderBy(F.asc(\"Test_ID\"))\n",
    "final_df = final_df.withColumn(\"Date\", F.date_format(F.col(\"Date\"), \"yyyy-MM-dd\"))\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the modified dataframe to csv. \n",
    "## Spark write function will split the workload and save the output spread out over multiple parts\n",
    "## Using cat and >  we will generate a single output file\n",
    "final_df.write.mode(\"overwrite\").csv('output/attempts/decisiontree-regressor101-5')\n",
    "os.system('rm output/attempts/decisiontree-regressor101-5.csv')\n",
    "os.system('cat output/attempts/decisiontree-regressor101-5/p* > output/attempts/decisiontree-regressor-101-5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
